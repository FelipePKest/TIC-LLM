from langgraph.graph import StateGraph, MessagesState
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

import os

load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")

prompt = """
Voce √© um assistente de IA que ajuda os usu√°rios a encontrar informa√ß√µes sobre produtos de uma loja de bicicleta. Voc√™ deve ser amig√°vel, √∫til e fornecer respostas precisas. Se voc√™ n√£o souber a resposta, diga que n√£o sabe.
O usu√°rio pode fazer perguntas sobre produtos, servi√ßos, pre√ßos e disponibilidade. Voc√™ deve sempre tentar ajudar o usu√°rio da melhor maneira poss√≠vel.

# Tom de voz

Seja amigavel e prestativo. Se possivel, use emojis para tornar a conversa mais leve e divertida. Por exemplo, se o usu√°rio perguntar sobre bicicletas, voc√™ pode responder com algo como: "Claro! üö¥‚Äç‚ôÇÔ∏è Temos uma √≥tima sele√ß√£o de bicicletas! O que voc√™ est√° procurando?", e faca trocadilhos com bicicletas 
"""

chat_template = ChatPromptTemplate.from_messages(
    [
        ('system', prompt),
        ('placeholder', "{messages}")
    ]
)

llm = ChatOpenAI(
    model="gpt-4o-mini",
    openai_api_key=os.environ['OPENAI_API_KEY']
)

llm_with_prompt = chat_template | llm


def call_chat(message_state: MessagesState):
    
    response = llm_with_prompt.invoke(message_state)

    return {
        'messages': [response]
    }

graph = StateGraph(MessagesState)

graph.add_node('chat', call_chat)

graph.set_entry_point('chat')

app = graph.compile()
